#[INFO]
Prompt file 2/2

            elif s.type == "tree":
                texts.append(f"#[PROJECT TREE]\n{s.content}\n\n")
            elif s.type == "file":
                texts.append(f"#[FILE] {s.path}\n{s.content}\n\n")
        return texts
    
    def _format_stats(self, stats: FilterStats) -> str:
        """
        Formats FilterStats readably.
        Shows number of files and total size in B/KB/MB.
        """
        size = stats.size
        if size >= 1024**2:  
            size_str = f"{size / (1024**2):.2f} MB"
        elif size >= 1024:   
            size_str = f"{size / 1024:.2f} KB"
        else:               
            size_str = f"{size} B"

        return f"files: {stats.files}, total size: {size_str}"

#[FILE] src\snib\models.py
from pathlib import Path
from dataclasses import dataclass
from typing import Optional

@dataclass
class FilterStats:
    type: str
    files: int = 0
    size: int = 0

@dataclass
class Section:
    type: str
    content: str = ""   
    path: Optional[Path] = None
    include: Optional[list[str]] = None
    exclude: Optional[list[str]] = None
    include_stats: Optional[FilterStats] = None
    exclude_stats: Optional[FilterStats] = None




#[FILE] src\snib\scanner.py
from pathlib import Path
import logging

from .models import Section, FilterStats
from .formatter import Formatter
from .chunker import Chunker
from .writer import Writer
from .utils import build_tree

logger = logging.getLogger(__name__)

class Scanner:
    def __init__(self, path: Path, config: dict): # TODO: add config to all module classes constructors if needed
        self.path = Path(path).resolve()
        self.config = config

    def _collect_sections(self, description, include, exclude, task) -> list[Section]:

        logger.debug("Collecting sections")

        #included_files = self._get_included_files(self.path, include, exclude)
        #excluded_files = self._get_included_files(self.path, exclude, include)
        all_files = [f for f in self.path.rglob("*") if f.is_file()]
        included_files = self._get_included_files(self.path, include, exclude)
        excluded_files = [f for f in all_files if f not in included_files]

        include_stats = self._calculate_filter_stats(included_files, "included")
        exclude_stats = self._calculate_filter_stats(excluded_files, "excluded")

        task_dict = self.config["instruction"]["task_dict"]
        instruction = task_dict.get(task, "")

        sections: list[Section] = []

        sections.append(Section(type="description", content=description))
        sections.append(Section(type="task", content=instruction))
        sections.append(Section(type="filters", include=include, exclude=exclude, include_stats=include_stats, exclude_stats=exclude_stats))
        sections.append(Section(type="tree", content="\n".join(build_tree(path=self.path, include=include, exclude=exclude))))

        for file_path in self._get_included_files(self.path, include, exclude):
            try:
                content = file_path.read_text(encoding="utf-8")
            except Exception:
                content = f"<Could not read {file_path.name}>\n"
            sections.append(Section(type="file", path=file_path.relative_to(self.path), content=content))

        logger.debug(f"Collected {len(sections)} sections")

        return sections
    
    """
    def _file_matches_filters(self, path: Path, include: list[str], exclude: list[str]) -> bool:
        for pattern in exclude:
            # file itself or full match
            if path.match(pattern) or path.name == pattern:
                return False
            # NEW: also test folder names in the path!!!
            if any(part == pattern for part in path.parts):
                return False
            
        if include:
            return any(path.match(pattern) or path.name == pattern for pattern in include)

        return True
    """

    def _file_matches_filters(self, path: Path, include: list[str], exclude: list[str]) -> bool:
        for pattern in exclude:
            # check full path vs glob + filename correct + foldernames check
            if path.match(pattern) or path.name == pattern or pattern in path.parts:
                return False
            
        if include:
            for pattern in include:
                # same here
                if path.match(pattern) or path.name == pattern or pattern in path.parts:
                    return True

            return False  # nothing matched

        # default: if no include -> allow all
        return True

    def _get_included_files(self, path: Path, include: list[str], exclude: list[str]) -> list[Path]:
        matching_files = []

        for file in path.rglob("*"):
            if not file.is_file():
                continue
            if self._file_matches_filters(path=file, include=include, exclude=exclude):
                matching_files.append(file)
        
        return matching_files

    def _calculate_filter_stats(self, files: list[Path], type_label: str) -> FilterStats:
        """
        Calculates FilterStats for a list of files.
        type_label: "included" or "excluded"
        """
        stats = FilterStats(type=type_label)

        for f in files:
            if f.is_file():
                stats.files += 1
                stats.size += f.stat().st_size

        return stats

    def scan(self, description, include, exclude, chunk_size, output_dir, force, task):

        logger.info(f"Scanning {self.path}")

        sections = self._collect_sections(description, include, exclude, task)
        formatter = Formatter()
        formatted = formatter.to_prompt_text(sections)

        chunker = Chunker(chunk_size)
        chunks = chunker.chunk(formatted)

        # leave headspace for header 100 chars in chunker -> self.header_size
        # insert header on first lines of every chunk

        chunks_with_header = []

        total = len(chunks)
        for i, chunk in enumerate(chunks, 1):
            if total <= 1:
                header = ""
            else:
                header = f"Please do not give output until all prompt files are sent. Prompt file {i}/{total}\n" if i == 1 else f"Prompt file {i}/{total}\n"

            # works with empty info section
            info_texts = formatter.to_prompt_text([Section(type="info", content=header)])
            if info_texts:
                chunks_with_header.append(info_texts[0] + chunk)
            else:
                chunks_with_header.append(chunk)

            #chunks_with_header.append(formatter.to_prompt_text([Section(type="info", content=header)])[0] + chunk)
                
        writer = Writer(output_dir)
        writer.write_chunks(chunks_with_header, force=force)

#[FILE] src\snib\utils.py
import logging
from pathlib import Path
import fnmatch
from click import Choice
import toml
from importlib import resources

from . import presets  # reference to snib.presets
from .config import DEFAULT_CONFIG, load_config

logger = logging.getLogger(__name__)

def handle_include_args(include_list):
    include_list = [i.strip() for i in include_list if i.strip()]
    
    if include_list and include_list[0].lower() != "all":
        logging.debug(f"User include list: {include_list}")
    else:
        include_list = []
        logging.debug("No user include list or 'all' specified.")

    return include_list

def handle_exclude_args(exclude_list):
    exclude_list = [e.strip() for e in exclude_list if e.strip()]
    
    if exclude_list:
        logging.debug(f"User exclude list: {exclude_list}")
    else:
        logging.debug("No user exclude list specified.")
        
    return exclude_list

def build_tree(path: Path, include: list[str], exclude: list[str], prefix: str = "") -> list[str]:
    """
    Builds a tree representation of the directory with include/exclude filters.
    - Directories are only shown if they contain at least one valid file.
    - Files are only shown if they match the include patterns (or if include is empty = allow all).
    """
    ELBOW = "└──"
    TEE = "├──"
    PIPE_PREFIX = "│   "
    SPACE_PREFIX = "    "

    """
    def should_include_file(entry: Path) -> bool:
        if any(entry.match(p) or entry.name == p for p in exclude):
            return False
        if entry.is_file():
            return not include or any(entry.match(p) or entry.name == p for p in include)
        return True  # dirs -> first yes, then check later
    """

    def should_include_file(entry: Path) -> bool:
        # excluded?
        if any(entry.match(p) or entry.name == p for p in exclude):
            return False

        # only files, if include empty or match
        if entry.is_file():
            return not include or any(entry.match(p) or entry.name == p or p in entry.parts for p in include)

        # folder: show if 
        #    - include emptry or
        #    - foldername itself in or
        #    - any file below matches include
        if entry.is_dir():
            if not include or entry.name in include:
                return True
            # min. one file below matches include
            return any(f.match(p) or f.name == p for p in include for f in entry.rglob("*") if f.is_file())

        return True

    lines = [path.name] if not prefix else []
    entries = [e for e in sorted(path.iterdir(), key=lambda p: (p.is_file(), p.name.lower())) if should_include_file(e)]

    for i, entry in enumerate(entries):
        connector = ELBOW if i == len(entries) - 1 else TEE
        line = f"{prefix}{connector} {entry.name}"

        if entry.is_dir():
            extension = SPACE_PREFIX if i == len(entries) - 1 else PIPE_PREFIX
            subtree = build_tree(entry, include, exclude, prefix + extension)
            if len(subtree) > 0:   # only append if not empty
                lines.append(line)
                lines.extend(subtree)
        else:
            lines.append(line)

    return lines

def format_size(size: int) -> str:
    """Return human-readable size string."""
    if size >= 1024**2:
        return f"{size / (1024**2):.2f} MB"
    elif size >= 1024:
        return f"{size / 1024:.2f} KB"
    return f"{size} B"

def detect_pattern_conflicts(includes: list[str], excludes: list[str]) -> set[str]:
    conflicts = set()
    # check each include against each exclude
    for inc in includes:
        for exc in excludes:
            # exact match
            if inc == exc:
                conflicts.add(inc)
            # include eaten by exclude
            elif fnmatch.fnmatch(inc, exc):
                conflicts.add(f"{inc} (matched by {exc})")
            # exclude is more specific than include -> overwritten
            elif fnmatch.fnmatch(exc, inc):
                conflicts.add(f"{inc} (conflicts with {exc})")
    return conflicts

def check_include_in_exclude(path: Path, includes: list[str], excludes: list[str]) -> list[str]:
    """
    Checks whether include patterns contain files that are located in an exclude folder.
    Returns the problematic includes.
    """
    problematic = []

    for inc in includes:
        inc_path = path / inc
        if not inc_path.exists():
            continue
        for exc in excludes:
            exc_path = path / exc
            # only check folders
            if exc_path.is_dir() and exc_path in inc_path.parents:
                problematic.append(inc)
    return problematic

def get_task_choices() -> list[str]:
    try:
        config = load_config()
        return Choice(list(config["instruction"]["task_dict"].keys()))
    except FileNotFoundError:
        return Choice(list(DEFAULT_CONFIG["instruction"]["task_dict"].keys()))
    
def load_preset(name: str) -> dict: #TODO: move to config.py
    preset_file = f"{name}.toml"
    try:
        with resources.open_text(presets, preset_file) as f:
            return toml.load(f)
    except FileNotFoundError:
        raise ValueError(f"Preset '{name}' not found")
    
def get_preset_choices() -> list[str]:
    """Return available preset names without extension."""
    try:
        files = resources.files(presets).iterdir()
        return Choice([f.name.rsplit(".", 1)[0] for f in files if f.name.endswith(".toml")])
    except FileNotFoundError:
        # if package is not installed right
        return []

#[FILE] src\snib\writer.py
import logging
from pathlib import Path

from .utils import format_size

logger = logging.getLogger(__name__)

class Writer:
    def __init__(self, output_dir: str):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def write_chunks(self, chunks: list[str], force: bool = False, ask_user: bool = True) -> list[Path]:
        """
        Writes chunks to text files in the output directory.
        - force: overwrite existing files without asking
        - ask_user: prompt user for confirmation (ignored if force=True)
        """
        logger.debug(f"Begin writing {len(chunks)} chunk(s) to {self.output_dir}")

        # Clear existing prompt files if needed
        if any(self.output_dir.glob("prompt_*.txt")):
            if force:
                self.clear_output()
            elif ask_user:
                if input(f"Output directory '{self.output_dir}' contains prompt file(s). Clear them? [y/N]: ").lower() == 'y':
                    self.clear_output()

        txt_files = []

        total_size = sum(len(c.encode("utf-8")) for c in chunks)
        size_str = format_size(total_size)

        # Ask before writing
        if not force and ask_user:
            proceed = input(f"Do you want to write {len(chunks)} prompt file(s) (total size {size_str}) to '{self.output_dir}'? [y/N]: ").lower()
            if proceed != 'y':
                logger.info("User aborted writing prompt files.")
                return []

        for i, chunk in enumerate(chunks, 1):
            filename = self.output_dir / f"prompt_{i}.txt"
            filename.write_text(chunk, encoding="utf-8")
            txt_files.append(filename)

        logger.info(f"Wrote {len(txt_files)} text file(s) to {self.output_dir}")
        return txt_files

    def clear_output(self):
        for file_path in self.output_dir.glob("prompt_*.txt"):
            if file_path.is_file():
                file_path.unlink()
        logger.info(f"Cleared existing prompt file(s) in {self.output_dir}")


#[FILE] src\snib\__init__.py


#[FILE] src\snib\__main__.py
from .cli import app

if __name__ == "__main__":
    app()

#[FILE] src\snib\presets\unity.toml
[project]
path = "."
description = ""

[instruction]
task = ""

[filters]
include = ["*.cs", "*.shader", "*.prefab", "*.unity"]
exclude = ["*.log", "*.meta", "Library", "Temp", "obj"]
smart_include = []
smart_exclude = []
default_exclude = ["venv", "promptready", ".git"]
no_default_exclude = false
smart = false

[output]
dir = "promptready"
chunk_size = 30000
force = false

[ai]
model = "gpt-4"

[instruction.task_dict]
debug = "Debug: Analyze the code and highlight potential errors, bugs, or inconsistencies."
comment = "Comment: Add comments or explain existing functions and code sections."
refactor = "Refactor: Suggest refactorings to make the code cleaner, more readable, and maintainable."
optimize = "Optimize: Improve efficiency or performance of the code."
summarize = "Summarize: Provide a concise summary of the files or modules."
document = "Document: Generate documentation for functions, classes, or modules."
test = "Test: Create unit tests or test cases for the code."
analyze = "Analyze: Perform static analysis or security checks on the code."

#[FILE] src\snib\presets\unreal.toml


